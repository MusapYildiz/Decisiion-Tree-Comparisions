# Trees and Forests

This repository contains a Jupyter Notebook that demonstrates training and visualizing Decision Tree classifiers on a customer segmentation dataset. The notebook covers data loading, preprocessing, model training with different impurity criteria, custom implementation of entropy-based trees, and graphical rendering of the resulting tree structures.

## Contents

* `Trees and Forests.ipynb`
  The main notebook with code sections for:

  1. Loading and inspecting the `teleCust1000t.csv` dataset
  2. Splitting data into training and test sets
  3. Training DecisionTreeClassifier with Gini and Entropy criteria
  4. Implementing a custom decision tree using entropy and information gain
  5. Generating predictions and evaluating accuracy and confusion matrices
  6. Visualizing the custom and scikit-learn trees via `pydotplus` and Graphviz

* `teleCust1000t.csv`
  Customer dataset with features such as region, tenure, age, income, and customer category labels.

## Setup

1. **Clone the repository**

   ```bash
   git clone https://github.com/USERNAME/REPO_NAME.git
   cd REPO_NAME
   ```

2. **Create a Python environment**
   It's recommended to use `venv` or `conda`:

   ```bash
   python3 -m venv venv
   source venv/bin/activate  # On Windows use `venv\Scripts\activate`
   ```

3. **Install dependencies**

   ```bash
   pip install -r requirements.txt
   ```

   If a `requirements.txt` is not present, manually install:

   ```bash
   pip install numpy pandas matplotlib scikit-learn pydotplus graphviz
   ```

4. **Install Graphviz system package**
   For macOS (Homebrew):

   ```bash
   brew install graphviz
   ```

   On Ubuntu/Debian:

   ```bash
   sudo apt-get update
   sudo apt-get install graphviz
   ```

## Usage

1. Launch Jupyter Notebook:

   ```bash
   jupyter notebook Trees\ and\ Forests.ipynb
   ```

2. Run each cell in order. The notebook will:

   * Load and display the first rows of the dataset
   * Show class distribution
   * Split data for training and testing
   * Train two scikit-learn decision tree models (Gini and Entropy)
   * Compute and print accuracy scores and confusion matrices
   * Build a custom decision tree implementation from scratch
   * Visualize both the custom and scikit-learn models side-by-side

3. Inspect the generated tree images directly within the notebook output.

## Code Structure

* **Data loading**: Uses `pandas.read_csv` to load `teleCust1000t.csv`.
* **Preprocessing**: Converts categorical and numerical features into NumPy arrays for scikit-learn.
* **Model training**: Utilizes `DecisionTreeClassifier` with default (Gini) and `criterion='entropy'` options.
* **Custom tree**: Contains functions to compute entropy, split data, calculate information gain, find best splits, and recursively build the tree.
* **Prediction & evaluation**: Uses `accuracy_score` and `confusion_matrix` for performance metrics.
* **Visualization**: Employs `pydotplus` and Graphviz to draw both custom and scikit-learn trees.

## Dataset Description

The `teleCust1000t.csv` file includes 1000 customer records. Each record has the following columns:

| Feature | Description                          |
| ------- | ------------------------------------ |
| region  | Geographic region code (categorical) |
| tenure  | Number of months as a customer       |
| age     | Customer age                         |
| marital | Marital status code (categorical)    |
| address | Number of years at current address   |
| income  | Annual income (thousands)            |
| ed      | Education level code (categorical)   |
| employ  | Years of employment                  |
| retire  | Retirement status code (categorical) |
| gender  | Gender code (categorical)            |
| reside  | Type of residence code (categorical) |
| custcat | Customer category label (target)     |

## Notes

* The custom tree implementation demonstrates the underlying mechanics of entropy and information gain but is not optimized for large datasets.
* For production use, rely on scikit-learnâ€™s highly optimized `DecisionTreeClassifier`.

## License

This project is released under the MIT License. Feel free to reuse and modify the code.

---

*Original notebook generated by Google Colab. Location: [https://colab.research.google.com/drive/185XjoWxSLrmtKIs5ngkqORV93u71bte9](https://colab.research.google.com/drive/185XjoWxSLrmtKIs5ngkqORV93u71bte9)*
